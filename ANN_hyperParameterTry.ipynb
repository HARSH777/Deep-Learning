{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Activation\n",
    "import pandas as pd\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= dataset.iloc[:,3:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= dataset.iloc[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "geo = pd.get_dummies(X['Geography'], drop_first='true')\n",
    "gen =pd.get_dummies(X['Gender'], drop_first='true')\n",
    "X=pd.concat([X, geo, gen], axis=1)\n",
    "X = X.drop(['Geography', 'Gender'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "X_train =sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  create_model(layers, activation):\n",
    "    model = Sequential()\n",
    "    for i, nodes in enumerate(layers):\n",
    "        if i==0:\n",
    "            model.add(Dense(nodes, input_dim=X.shape[1]))\n",
    "            model.add(Activation(activation))\n",
    "            model.add(Dropout(0.3))\n",
    "        else:\n",
    "            model.add(Dense(nodes))\n",
    "            model.add(Activation(activation))\n",
    "            model.add(Dropout(0.3))\n",
    "        model.add(Dense(1, activation='sigmoid', kernel_initializer ='glorot_uniform'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(layers = [[3,4],[1,2]], activation=['sigmoid', 'leaky_relu'],batch_size =[10, 30], epochs=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator= classifier, param_grid=params, cv =10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/harsh/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harsh/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harsh/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harsh/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/harsh/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harsh/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 484us/step - loss: 0.5588 - acc: 0.7594\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 176us/step - loss: 0.5213 - acc: 0.7971\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 181us/step - loss: 0.5172 - acc: 0.7971\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 175us/step - loss: 0.5092 - acc: 0.7971\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 175us/step - loss: 0.5010 - acc: 0.7971\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 176us/step - loss: 0.4959 - acc: 0.7971\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 182us/step - loss: 0.4924 - acc: 0.7971\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 195us/step - loss: 0.4894 - acc: 0.7971\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 177us/step - loss: 0.4847 - acc: 0.7971\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 178us/step - loss: 0.4780 - acc: 0.7971\n",
      "800/800 [==============================] - 0s 243us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 2s 273us/step - loss: 0.5448 - acc: 0.7908\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 193us/step - loss: 0.5146 - acc: 0.7967\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 211us/step - loss: 0.5121 - acc: 0.7967\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 211us/step - loss: 0.5030 - acc: 0.7967\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 202us/step - loss: 0.5046 - acc: 0.7967\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.5021 - acc: 0.7967\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.4982 - acc: 0.7967\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 193us/step - loss: 0.4931 - acc: 0.7967\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 202us/step - loss: 0.4887 - acc: 0.7967\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.4841 - acc: 0.7967\n",
      "800/800 [==============================] - 0s 203us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 2s 296us/step - loss: 0.6291 - acc: 0.6554\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 194us/step - loss: 0.5398 - acc: 0.7721\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 204us/step - loss: 0.5299 - acc: 0.7907\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 204us/step - loss: 0.5209 - acc: 0.7956\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 204us/step - loss: 0.5128 - acc: 0.7956\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 199us/step - loss: 0.5067 - acc: 0.7956\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.5042 - acc: 0.7956\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 199us/step - loss: 0.4973 - acc: 0.7956\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 196us/step - loss: 0.4914 - acc: 0.7956\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 194us/step - loss: 0.4872 - acc: 0.7956\n",
      "800/800 [==============================] - 0s 244us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 2s 294us/step - loss: 0.5440 - acc: 0.7818\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 194us/step - loss: 0.5181 - acc: 0.7975\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 195us/step - loss: 0.5165 - acc: 0.7975\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 189us/step - loss: 0.5138 - acc: 0.7975\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 196us/step - loss: 0.5049 - acc: 0.7975\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 196us/step - loss: 0.4958 - acc: 0.7975\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 197us/step - loss: 0.4895 - acc: 0.7975\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 196us/step - loss: 0.4850 - acc: 0.7975\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 196us/step - loss: 0.4781 - acc: 0.7975\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.4759 - acc: 0.7974\n",
      "800/800 [==============================] - 0s 293us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 2s 315us/step - loss: 0.6135 - acc: 0.6756\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5318 - acc: 0.7937\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 214us/step - loss: 0.5206 - acc: 0.7937\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 211us/step - loss: 0.5184 - acc: 0.7937\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 222us/step - loss: 0.5145 - acc: 0.7937\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5089 - acc: 0.7937\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 214us/step - loss: 0.5060 - acc: 0.7937\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 214us/step - loss: 0.5003 - acc: 0.7937\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.4990 - acc: 0.7937\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 214us/step - loss: 0.4912 - acc: 0.7937\n",
      "800/800 [==============================] - 0s 332us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 2s 341us/step - loss: 0.5839 - acc: 0.7126\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 219us/step - loss: 0.5229 - acc: 0.7944\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.5175 - acc: 0.7944\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 228us/step - loss: 0.5144 - acc: 0.7944\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 217us/step - loss: 0.5055 - acc: 0.7944\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5030 - acc: 0.7944\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 216us/step - loss: 0.4983 - acc: 0.7944\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 219us/step - loss: 0.4902 - acc: 0.7944\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.4835 - acc: 0.7944\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.4835 - acc: 0.7944\n",
      "800/800 [==============================] - 0s 383us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 368us/step - loss: 0.5482 - acc: 0.7692\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 224us/step - loss: 0.5198 - acc: 0.7969\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 198us/step - loss: 0.5131 - acc: 0.7969\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 195us/step - loss: 0.5091 - acc: 0.7969\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 210us/step - loss: 0.5014 - acc: 0.7969\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 203us/step - loss: 0.4966 - acc: 0.7969\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 212us/step - loss: 0.4907 - acc: 0.7969\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 199us/step - loss: 0.4837 - acc: 0.7969\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 203us/step - loss: 0.4783 - acc: 0.7969\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 199us/step - loss: 0.4738 - acc: 0.7969\n",
      "800/800 [==============================] - 0s 427us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 355us/step - loss: 0.5579 - acc: 0.7537\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 209us/step - loss: 0.5319 - acc: 0.7917\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 210us/step - loss: 0.5109 - acc: 0.7962\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 210us/step - loss: 0.5029 - acc: 0.7962\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 207us/step - loss: 0.4982 - acc: 0.7962\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 209us/step - loss: 0.4872 - acc: 0.7962\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 208us/step - loss: 0.4838 - acc: 0.7962\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 206us/step - loss: 0.4776 - acc: 0.7962\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 211us/step - loss: 0.4733 - acc: 0.7962\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 209us/step - loss: 0.4688 - acc: 0.7962\n",
      "800/800 [==============================] - 0s 463us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 360us/step - loss: 0.7809 - acc: 0.4711\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 212us/step - loss: 0.5384 - acc: 0.7957\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5203 - acc: 0.7957\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 209us/step - loss: 0.5148 - acc: 0.7957\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 209us/step - loss: 0.5102 - acc: 0.7957\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 212us/step - loss: 0.5100 - acc: 0.7957\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 210us/step - loss: 0.5072 - acc: 0.7957\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 212us/step - loss: 0.5056 - acc: 0.7957\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 219us/step - loss: 0.5034 - acc: 0.7957\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 209us/step - loss: 0.4983 - acc: 0.7957\n",
      "800/800 [==============================] - 0s 513us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 376us/step - loss: 0.5840 - acc: 0.7181\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5193 - acc: 0.7961\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5143 - acc: 0.7961\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5092 - acc: 0.7961\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 219us/step - loss: 0.5017 - acc: 0.7961\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 219us/step - loss: 0.4968 - acc: 0.7961\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 216us/step - loss: 0.4941 - acc: 0.7961\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 216us/step - loss: 0.4883 - acc: 0.7961\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.4884 - acc: 0.7961\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 217us/step - loss: 0.4824 - acc: 0.7961\n",
      "800/800 [==============================] - 0s 553us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 392us/step - loss: 0.6043 - acc: 0.6967\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.5317 - acc: 0.7971\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 217us/step - loss: 0.5177 - acc: 0.7971\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 219us/step - loss: 0.5141 - acc: 0.7971\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 219us/step - loss: 0.5085 - acc: 0.7971\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.5064 - acc: 0.7971\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 217us/step - loss: 0.5060 - acc: 0.7971\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.5041 - acc: 0.7971\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 220us/step - loss: 0.5041 - acc: 0.7971\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.4990 - acc: 0.7971\n",
      "800/800 [==============================] - 0s 595us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 407us/step - loss: 0.6301 - acc: 0.6815\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.5199 - acc: 0.7967\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 225us/step - loss: 0.5078 - acc: 0.7967\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 211us/step - loss: 0.5059 - acc: 0.7967\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 209us/step - loss: 0.5028 - acc: 0.7967\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 220us/step - loss: 0.5065 - acc: 0.7967\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 214us/step - loss: 0.5025 - acc: 0.7967\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 209us/step - loss: 0.5014 - acc: 0.7967\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 224us/step - loss: 0.5020 - acc: 0.7967\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 205us/step - loss: 0.5007 - acc: 0.7967\n",
      "800/800 [==============================] - 1s 626us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 431us/step - loss: 0.6278 - acc: 0.6506\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 240us/step - loss: 0.5339 - acc: 0.7956\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 240us/step - loss: 0.5210 - acc: 0.7956\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 252us/step - loss: 0.5125 - acc: 0.7956\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 235us/step - loss: 0.5103 - acc: 0.7956\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 238us/step - loss: 0.5074 - acc: 0.7956\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 238us/step - loss: 0.5050 - acc: 0.7956\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 236us/step - loss: 0.5025 - acc: 0.7956\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 240us/step - loss: 0.5001 - acc: 0.7956\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 245us/step - loss: 0.4978 - acc: 0.7956\n",
      "800/800 [==============================] - 1s 690us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 433us/step - loss: 0.5310 - acc: 0.7975\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 233us/step - loss: 0.5264 - acc: 0.7975\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 239us/step - loss: 0.5151 - acc: 0.7975\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 236us/step - loss: 0.5150 - acc: 0.7975\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 236us/step - loss: 0.5083 - acc: 0.7975\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 232us/step - loss: 0.5047 - acc: 0.7975\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 235us/step - loss: 0.4999 - acc: 0.7975\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 233us/step - loss: 0.4968 - acc: 0.7975\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 232us/step - loss: 0.4940 - acc: 0.7975\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 232us/step - loss: 0.4925 - acc: 0.7975\n",
      "800/800 [==============================] - 1s 741us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 3s 434us/step - loss: 0.6079 - acc: 0.6778\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.5391 - acc: 0.7937\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 216us/step - loss: 0.5240 - acc: 0.7937\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 213us/step - loss: 0.5201 - acc: 0.7937\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 216us/step - loss: 0.5179 - acc: 0.7937\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5130 - acc: 0.7937\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5119 - acc: 0.7937\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 216us/step - loss: 0.5129 - acc: 0.7937\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.5108 - acc: 0.7937\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 220us/step - loss: 0.5093 - acc: 0.7937\n",
      "800/800 [==============================] - 1s 769us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 465us/step - loss: 0.5690 - acc: 0.7747\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 236us/step - loss: 0.5283 - acc: 0.7944\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 229us/step - loss: 0.5167 - acc: 0.7944\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 238us/step - loss: 0.5154 - acc: 0.7944\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 230us/step - loss: 0.5115 - acc: 0.7944\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 240us/step - loss: 0.5100 - acc: 0.7944\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 230us/step - loss: 0.5093 - acc: 0.7944\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 239us/step - loss: 0.5089 - acc: 0.7944\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 232us/step - loss: 0.5070 - acc: 0.7944\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 244us/step - loss: 0.5061 - acc: 0.7944\n",
      "800/800 [==============================] - 1s 825us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 464us/step - loss: 0.6158 - acc: 0.6631\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 236us/step - loss: 0.5315 - acc: 0.7969\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 289us/step - loss: 0.5198 - acc: 0.7969\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 256us/step - loss: 0.5139 - acc: 0.7969\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 280us/step - loss: 0.5091 - acc: 0.7969\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 248us/step - loss: 0.5081 - acc: 0.7969\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 232us/step - loss: 0.5077 - acc: 0.7969\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 231us/step - loss: 0.5057 - acc: 0.7969\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 275us/step - loss: 0.5027 - acc: 0.7969\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 256us/step - loss: 0.5016 - acc: 0.7969\n",
      "800/800 [==============================] - 1s 859us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 469us/step - loss: 0.5930 - acc: 0.7562\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 220us/step - loss: 0.5206 - acc: 0.7962\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 260us/step - loss: 0.5138 - acc: 0.7962\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 301us/step - loss: 0.5139 - acc: 0.7962\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 391us/step - loss: 0.5100 - acc: 0.7962\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 253us/step - loss: 0.5097 - acc: 0.7962\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 276us/step - loss: 0.5074 - acc: 0.7962\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 281us/step - loss: 0.5090 - acc: 0.7962\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 232us/step - loss: 0.5069 - acc: 0.7962\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 225us/step - loss: 0.5068 - acc: 0.7962\n",
      "800/800 [==============================] - 1s 884us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 479us/step - loss: 0.5873 - acc: 0.7357\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 221us/step - loss: 0.5204 - acc: 0.7957\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 220us/step - loss: 0.5161 - acc: 0.7957\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 235us/step - loss: 0.5116 - acc: 0.7957\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 230us/step - loss: 0.5055 - acc: 0.7957\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 220us/step - loss: 0.5031 - acc: 0.7957\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 219us/step - loss: 0.4996 - acc: 0.7957\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 225us/step - loss: 0.4974 - acc: 0.7957\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 224us/step - loss: 0.4962 - acc: 0.7957\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 245us/step - loss: 0.4940 - acc: 0.7957\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 504us/step - loss: 0.6001 - acc: 0.7026\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 241us/step - loss: 0.5323 - acc: 0.7961\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 249us/step - loss: 0.5177 - acc: 0.7961\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 270us/step - loss: 0.5164 - acc: 0.7961\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 238us/step - loss: 0.5119 - acc: 0.7961\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 258us/step - loss: 0.5105 - acc: 0.7961\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 292us/step - loss: 0.5085 - acc: 0.7961\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 225us/step - loss: 0.5053 - acc: 0.7961\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 224us/step - loss: 0.5039 - acc: 0.7961\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 253us/step - loss: 0.5023 - acc: 0.7961\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 354us/step - loss: 0.5521 - acc: 0.7657\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.5288 - acc: 0.7971\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.5208 - acc: 0.7971\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.5141 - acc: 0.7971\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.5155 - acc: 0.7971\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.5125 - acc: 0.7971\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.5080 - acc: 0.7971\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.5079 - acc: 0.7971\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.5028 - acc: 0.7971\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.5027 - acc: 0.7971\n",
      "800/800 [==============================] - 1s 985us/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.5996 - acc: 0.7035\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.5445 - acc: 0.7887\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5241 - acc: 0.7967\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.5235 - acc: 0.7967\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.5180 - acc: 0.7967\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.5129 - acc: 0.7967\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.5097 - acc: 0.7967\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.5099 - acc: 0.7967\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.5084 - acc: 0.7967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.5074 - acc: 0.7967\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 441us/step - loss: 0.7652 - acc: 0.4188\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.6062 - acc: 0.6914\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5489 - acc: 0.7932\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.5307 - acc: 0.7956\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.5248 - acc: 0.7956\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.5204 - acc: 0.7956\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.5153 - acc: 0.7956\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.5133 - acc: 0.7956\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.5087 - acc: 0.7956\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.5079 - acc: 0.7956\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 410us/step - loss: 0.8270 - acc: 0.3503\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.6283 - acc: 0.6656\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.5593 - acc: 0.7496\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5378 - acc: 0.7975\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 118us/step - loss: 0.5312 - acc: 0.7975\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.5179 - acc: 0.7975\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.5155 - acc: 0.7975\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.5104 - acc: 0.7975\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 111us/step - loss: 0.5108 - acc: 0.7975\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.5105 - acc: 0.7975\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 451us/step - loss: 0.9346 - acc: 0.3018\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.6825 - acc: 0.5836\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.5933 - acc: 0.6686\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.5568 - acc: 0.7521\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.5419 - acc: 0.7937\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.5352 - acc: 0.7937\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.5326 - acc: 0.7937\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.5290 - acc: 0.7937\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.5258 - acc: 0.7937\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.5192 - acc: 0.7937\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 412us/step - loss: 0.6206 - acc: 0.6893\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.5387 - acc: 0.7818\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.5293 - acc: 0.7943\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.5203 - acc: 0.7944\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.5203 - acc: 0.7944\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.5153 - acc: 0.7944\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.5099 - acc: 0.7944\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.5058 - acc: 0.7944\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.5037 - acc: 0.7944\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.4985 - acc: 0.7944\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 429us/step - loss: 0.7672 - acc: 0.4278\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.5931 - acc: 0.7218\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.5359 - acc: 0.7658\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.5332 - acc: 0.7892\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.5263 - acc: 0.7969\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.5179 - acc: 0.7969\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.5180 - acc: 0.7969\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.5112 - acc: 0.7969\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.5118 - acc: 0.7969\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.5082 - acc: 0.7969\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 441us/step - loss: 0.6241 - acc: 0.6746\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.5480 - acc: 0.7962\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.5223 - acc: 0.7962\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.5205 - acc: 0.7962\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.5119 - acc: 0.7962\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.5067 - acc: 0.7962\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.5050 - acc: 0.7962\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.4980 - acc: 0.7962\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.4917 - acc: 0.7962\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.4906 - acc: 0.7962\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 471us/step - loss: 0.8004 - acc: 0.3440\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.6146 - acc: 0.7203\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.5461 - acc: 0.7951\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.5269 - acc: 0.7957\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.5201 - acc: 0.7957\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 114us/step - loss: 0.5197 - acc: 0.7957\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.5168 - acc: 0.7957\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5133 - acc: 0.7957\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.5140 - acc: 0.7957\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 111us/step - loss: 0.5108 - acc: 0.7957\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 469us/step - loss: 0.5270 - acc: 0.7896\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.5241 - acc: 0.7940\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.5203 - acc: 0.7961\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.5183 - acc: 0.7961\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.5156 - acc: 0.7961\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.5163 - acc: 0.7961\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.5161 - acc: 0.7961\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.5170 - acc: 0.7961\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 114us/step - loss: 0.5144 - acc: 0.7961\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.5098 - acc: 0.7961\n",
      "800/800 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 525us/step - loss: 0.9685 - acc: 0.2976\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 109us/step - loss: 0.7724 - acc: 0.3721\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.6561 - acc: 0.5954\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.5892 - acc: 0.7971\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.5507 - acc: 0.7971\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.5276 - acc: 0.7971\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.5184 - acc: 0.7971\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.5116 - acc: 0.7971\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.5096 - acc: 0.7971\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.5062 - acc: 0.7971\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 490us/step - loss: 0.8254 - acc: 0.3538\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.6718 - acc: 0.5442\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.5871 - acc: 0.7967\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.5460 - acc: 0.7967\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.5273 - acc: 0.7967\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.5206 - acc: 0.7967\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.5150 - acc: 0.7967\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.5120 - acc: 0.7967\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.5124 - acc: 0.7967\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.5122 - acc: 0.7967\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 503us/step - loss: 0.5532 - acc: 0.7956\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.5308 - acc: 0.7956\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.5199 - acc: 0.7956\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.5228 - acc: 0.7956\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.5189 - acc: 0.7956\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.5180 - acc: 0.7956\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5147 - acc: 0.7956\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5135 - acc: 0.7956\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5101 - acc: 0.7956\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5124 - acc: 0.7956\n",
      "800/800 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 526us/step - loss: 0.6756 - acc: 0.5915\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5812 - acc: 0.6715\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.5511 - acc: 0.7939\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.5316 - acc: 0.7975\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.5269 - acc: 0.7975\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.5225 - acc: 0.7975\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5167 - acc: 0.7975\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.5141 - acc: 0.7975\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.5149 - acc: 0.7975\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.5095 - acc: 0.7975\n",
      "800/800 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 519us/step - loss: 0.6448 - acc: 0.6631\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.5730 - acc: 0.6724\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.5457 - acc: 0.7726\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.5417 - acc: 0.7937\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.5335 - acc: 0.7937\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.5328 - acc: 0.7937\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.5187 - acc: 0.7937\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.5238 - acc: 0.7937\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.5204 - acc: 0.7937\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.5146 - acc: 0.7937\n",
      "800/800 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 541us/step - loss: 0.6147 - acc: 0.6711\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5583 - acc: 0.7300\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5397 - acc: 0.7944\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.5356 - acc: 0.7944\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.5265 - acc: 0.7944\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.5216 - acc: 0.7944\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.5224 - acc: 0.7944\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.5173 - acc: 0.7944\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.5182 - acc: 0.7944\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.5123 - acc: 0.7944\n",
      "800/800 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 550us/step - loss: 0.5473 - acc: 0.7969\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5285 - acc: 0.7969\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5253 - acc: 0.7969\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.5235 - acc: 0.7969\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.5173 - acc: 0.7969\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.5141 - acc: 0.7969\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.5149 - acc: 0.7969\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.5119 - acc: 0.7969\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.5082 - acc: 0.7969\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5079 - acc: 0.7969\n",
      "800/800 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 574us/step - loss: 0.7116 - acc: 0.5128\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.5956 - acc: 0.6771\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.5520 - acc: 0.7962\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5345 - acc: 0.7962\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5241 - acc: 0.7962\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.5238 - acc: 0.7962\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5212 - acc: 0.7962\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.5177 - acc: 0.7962\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.5148 - acc: 0.7962\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.5132 - acc: 0.7962\n",
      "800/800 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 587us/step - loss: 0.6250 - acc: 0.7621\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.5533 - acc: 0.7957\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.5295 - acc: 0.7957\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.5185 - acc: 0.7957\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 109us/step - loss: 0.5170 - acc: 0.7957\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.5142 - acc: 0.7957\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.5158 - acc: 0.7957\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.5114 - acc: 0.7957\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.5141 - acc: 0.7957\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.5098 - acc: 0.7957\n",
      "800/800 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 586us/step - loss: 0.7046 - acc: 0.4933\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 109us/step - loss: 0.6055 - acc: 0.7961\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.5504 - acc: 0.7961\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.5265 - acc: 0.7961\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.5153 - acc: 0.7961\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.5149 - acc: 0.7961 0s - loss: 0.5159 -\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.5111 - acc: 0.7961\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.5100 - acc: 0.7961\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.5089 - acc: 0.7961\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.5073 - acc: 0.7961\n",
      "800/800 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown activation function:leaky_relu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-3949096c802a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 **self.filter_sk_params(self.build_fn.__call__))\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mloss_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-86983312b957>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(layers, activation)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activation, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/activations.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/activations.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         printable_module_name='activation function')\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 165\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown activation function:leaky_relu"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
